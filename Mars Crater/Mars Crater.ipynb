{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Crater\n",
    "This dataset was generated using HRSC nadir panchromatic image h0905_0000 taken by the Mars Express spacecraft. The images is located in the Xanthe Terra, centered on Nanedi Vallis and covers mostly Noachian terrain on Mars. The image had a resolution of 12.5 meters/pixel.\n",
    "## Problem statement\n",
    "Determine if the instance is a crater or not a crater. 1=Crater, 0=Not Crater\n",
    "\n",
    "## About the dataset\n",
    "Using the technique described by L. Bandeira (Bandeira, Ding, Stepinski. 2010.Automatic Detection of Sub-km Craters Using Shape and Texture Information) we identify crater candidates in the image using the pipeline depicted in the figure below. Each crater candidate image block is normalized to a standard scale of 48 pixels. Each of the nine kinds of image masks probes the normalized image block in four different scales of 12 pixels, 24 pixels, 36 pixels, and 48 pixels, with a step of a third of the mask size (meaning 2/3 overlap). We totally extract 1,090 Haar-like attributes using nine types of masks as the attribute vectors to represent each crater candidate. The dataset was converted to the Weka ARFF format by Joseph Paul Cohen in 2012.\n",
    "\n",
    "pipeline\n",
    "\n",
    "Attribute Information:\n",
    "We construct a attribute vector for each crater candidate using Haar-like attributes described by Papageorgiou 1998. These attributes are simple texture attributes which are calculated using Haar-like image masks that were used by Viola in 2004 for face detection consisting only black and white sectors. The value of an attribute is the difference between the sum of gray pixel values located within the black sector and the white sector of an image mask. The figure below shows nine image masks used in our case study. The first five masks focus on capturing diagonal texture gradient changes while the remaining four masks on horizontal or vertical textures.\n",
    "\n",
    "## How to read an image ?\n",
    "Python supports very powerful tools when comes to image processing.Matplotlib is an amazing visualization library in Python for 2D plots of arrays. Matplotlib is a multi-platform data visualization library built on NumPy arrays and designed to work with the broader SciPy stack. It was introduced by John Hunter in the year 2002. We will use Matplotlib library to convert the image to numpy as array.\n",
    "\n",
    "We import image from the Matplotlib library as mpimg.\n",
    "Use mpimg.imread to read the image as numpy as array.\n",
    "** INPUT **\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "<div class=\"w-percent-100 flex-hbox flex-cross-center flex-main-center\">\n",
    "          <div style=\"width:100%\" class=\"flex-auto\">\n",
    "            <div style=\"width:100%; max-width:100%; overflow: hidden \"><p><img src=\"https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b-43/9301164e-92b3-4f64-b699-737433839cd8/file.png\" alt=\"tile\" /></p></div>\n",
    "          </div>\n",
    "        </div>\n",
    "\n",
    "image = mpimg.imread('crater1.png')\n",
    "** OUTPUT **\n",
    "\n",
    "array([[0.40784314, 0.40784314, 0.40784314, ..., 0.42745098, 0.42745098,\n",
    "        0.42745098],\n",
    "       [0.4117647 , 0.4117647 , 0.4117647 , ..., 0.42745098, 0.42745098,\n",
    "        0.42745098],\n",
    "       [0.41960785, 0.41568628, 0.41568628, ..., 0.43137255, 0.43137255,\n",
    "        0.43137255],\n",
    "       ...,\n",
    "       [0.4392157 , 0.43529412, 0.43137255, ..., 0.45490196, 0.4509804 ,\n",
    "        0.4509804 ],\n",
    "       [0.44313726, 0.44313726, 0.4392157 , ..., 0.4509804 , 0.44705883,\n",
    "        0.44705883],\n",
    "       [0.44313726, 0.4509804 , 0.4509804 , ..., 0.44705883, 0.44705883,\n",
    "        0.44313726]], dtype=float32)\n",
    "NOTE : The images of the crater has already been converted to numpy array and is provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Preprocess the data\n",
    "The first step - you know the drill by now - load the dataset and see how it looks like. Additionally, split it into train and test set and standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      attr0     attr1      attr2      attr3      attr4  \\\n",
      "0           0  -4.049514 -5.055907   4.813832  10.975995  10.599993   \n",
      "1           1   3.514292  4.721218  -2.536391  -8.388817 -10.787064   \n",
      "2           2 -11.318180  9.405884  29.141795  21.277405  -5.122294   \n",
      "3           3  -7.143218 -9.869755  -7.905797   4.271652  22.890720   \n",
      "4           4  -5.027305  5.600857  10.312207   3.855865  -1.988057   \n",
      "\n",
      "       attr5      attr6     attr7      attr8  ...   attr1080   attr1081  \\\n",
      "0   8.103339   7.260105  3.984216  -3.352366  ...  39.055706  39.480231   \n",
      "1  -9.024258  -5.473323  7.646837  15.297336  ...  34.934308  34.224270   \n",
      "2 -21.736671 -12.850864  3.134460   7.207608  ...  86.905997  78.811334   \n",
      "3  28.454973  12.167586 -2.024773  -2.093635  ...  65.272842  63.522759   \n",
      "4   4.749132   9.700589  1.991069  -2.491197  ...  80.313460  77.703464   \n",
      "\n",
      "    attr1082    attr1083    attr1084    attr1085    attr1086    attr1087  \\\n",
      "0  48.177327   49.460693   50.797614   50.680413   44.778675   36.101397   \n",
      "1  42.633077   46.226847   49.730228   49.624121   45.398516   39.585452   \n",
      "2  84.165826   86.976997  116.149402  107.729029   96.534329   80.428859   \n",
      "3  67.886176   67.388943   93.066755   91.394297   70.704254   63.252282   \n",
      "4  93.575195  104.748562  129.462818  124.996294  118.110321  108.709732   \n",
      "\n",
      "     attr1088  attr1089  \n",
      "0   44.447948         0  \n",
      "1   45.971939         0  \n",
      "2  114.810516         0  \n",
      "3   82.057148         0  \n",
      "4  139.685624         0  \n",
      "\n",
      "[5 rows x 1091 columns]\n",
      "0.4646647584547681\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "path = './file.zip'\n",
    "# Code starts here\n",
    "# Read the data\n",
    "df = pd.read_csv(filepath_or_buffer=path,compression='zip')\n",
    "print(df.head())\n",
    "\n",
    "# Dependent variable\n",
    "y = df['attr1089']\n",
    "\n",
    "# Independent variable\n",
    "X = df.drop(columns=['attr1089'])\n",
    "\n",
    "# Split the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=4)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_test[45,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :  successfully loaded the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step  2 : Predict the values after building a Machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834042610697639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --------------\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "roc_score = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "print(roc_score)\n",
    "# Code ends here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result : successfully applied Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step  3 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732834218291986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# --------------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=4)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred=dt.predict(X_test)\n",
    "roc_score = roc_auc_score(y_test,y_pred)\n",
    "print(roc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :  successfully applied Decision tree model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Can we improve our model's performance with Random forrest algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072251284029547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Code strats here\n",
    "rfc = RandomForestClassifier(random_state=4)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "roc_score = roc_auc_score(y_test,y_pred)\n",
    "print(roc_score)\n",
    "# Code ends here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result : successfully applied Random Forrest model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Bagginng or Bootstrap aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8326817973710872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------\n",
    "# Import Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "# Code starts here\n",
    "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,max_samples=100,n_estimators=100)\n",
    "\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "\n",
    "score_bagging = bagging_clf.score(X_test,y_test)\n",
    "roc_score = roc_auc_score(y_test,bagging_clf.predict(X_test))\n",
    "print(roc_score)\n",
    "# Code ends here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result : successfully applied Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Voting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Import libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Various models\n",
    "clf_1 = LogisticRegression()\n",
    "clf_2 = DecisionTreeClassifier(random_state=4)\n",
    "clf_3 = RandomForestClassifier(random_state=4)\n",
    "\n",
    "model_list = [('lr',clf_1),('DT',clf_2),('RF',clf_3)]\n",
    "voting_clf_hard = VotingClassifier(estimators=model_list,voting='hard')\n",
    "voting_clf_hard.fit(X_train,y_train)\n",
    "hard_voting_score = voting_clf_hard.score(X_test,y_test)\n",
    "# Code starts here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result : successfully used Voting Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
